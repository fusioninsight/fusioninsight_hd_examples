<?xml version="1.0" encoding="UTF-8"?>
<configuration>
<property>
<name>dfs.nameservices.mappings</name>
<value>[{"name":"hacluster","roleInstances":["23","22"]}]</value>
</property>
<property>
<name>dfs.namenode.kerberos.principal.pattern</name>
<value>*</value>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.enable</name>
<value>true</value>
</property>
<property>
<name>dfs.nameservices</name>
<value>hacluster</value>
</property>
<property>
<name>dfs.client.retry.window.base</name>
<value>5</value>
</property>
<property>
<name>dfs.client.file-block-storage-locations.timeout.millis</name>
<value>600000</value>
</property>
<property>
<name>dfs.client.close.ack-timeout</name>
<value>900000</value>
</property>
<property>
<name>dfs.web.authentication.kerberos.principal</name>
<value>HTTP/_HOST@</value>
</property>
<property>
<name>dfs.client.socket-timeout</name>
<value>600000</value>
</property>
<property>
<name>dfs.client.socketcache.expiryMsec</name>
<value>900</value>
</property>
<property>
<name>dfs.datanode.socket.write.timeout</name>
<value>600000</value>
</property>
<property>
<name>dfs.client.failover.proxy.provider.hacluster</name>
<value>org.apache.hadoop.hdfs.server.namenode.ha.BlackListingFailoverProxyProvider</value>
</property>
<property>
<name>dfs.client.io-weight</name>
<value>10</value>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.policy</name>
<value>DEFAULT</value>
</property>
<property>
<name>dfs.webhdfs.enabled</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.rpc-address.hacluster.23</name>
<value>187-7-60-223:25000</value>
</property>
<property>
<name>dfs.namenode.rpc-address.hacluster.22</name>
<value>187-7-60-150:25000</value>
</property>
<property>
<name>dfs.ha.namenodes.hacluster</name>
<value>23,22</value>
</property>
<property>
<name>dfs.namenode.https.port</name>
<value>25003</value>
</property>
<property>
<name>ipc.client.connect.max.retries.on.timeouts</name>
<value>15</value>
</property>
<property>
<name>dfs.client.socketcache.capacity</name>
<value>0</value>
</property>
<property>
<name>dfs.blocksize</name>
<value>134217728</value>
</property>
<property>
<name>dfs.datanode.address</name>
<value>187-7-60-150:25009</value>
</property>
<property>
<name>dfs.ha.namenode.id</name>
<value>22</value>
</property>
<property>
<name>dfs.namenode.rpc.port</name>
<value>25000</value>
</property>
<property>
<name>dfs.datanode.data.dir.perm</name>
<value>700</value>
</property>
<property>
<name>dfs.client.datanode-restart.timeout</name>
<value>60</value>
</property>
<property>
<name>dfs.client-write-packet-size</name>
<value>262144</value>
</property>
<property>
<name>fs.permissions.umask-mode</name>
<value>066</value>
</property>
<property>
<name>dfs.datanode.socket.reuse.keepalive</name>
<value>-1</value>
</property>
<property>
<name>dfs.client.failover.max.attempts</name>
<value>10</value>
</property>
<property>
<name>dfs.datanode.http.address</name>
<value>187-7-60-150:25010</value>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.replication</name>
<value>2</value>
</property>
</configuration>
