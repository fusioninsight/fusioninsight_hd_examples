<?xml version="1.0" encoding="UTF-8"?><configuration>
<property>
<name>dfs.namenode.rpc-address.hacluster.100</name>
<value>8-5-214-7:25000</value>
</property>
<property>
<name>dfs.namenode.rpc-address.hacluster.101</name>
<value>8-5-214-8:25000</value>
</property>
<property>
<name>dfs.client.read.shortcircuit.skip.checksum</name>
<value>true</value>
</property>
<property>
<name>dfs.nameservices.mappings</name>
<value>[{"name":"hacluster","roleInstances":["100","101"]}]</value>
</property>
<property>
<name>dfs.namenode.kerberos.principal.pattern</name>
<value>*</value>
</property>
<property>
<name>dfs.replication</name>
<value>3</value>
</property>
<property>
<name>dfs.client.https.need-auth</name>
<value>false</value>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.enable</name>
<value>true</value>
</property>
<property>
<name>dfs.nameservices</name>
<value>hacluster,haclusterX,haclusterX1,haclusterX2,haclusterX3,haclusterX4</value>
</property>
<property>
<name>dfs.datanode.kerberos.https.principal</name>
<value>mapred/hadoop.hadoop.com@HADOOP.COM</value>
</property>
<property>
<name>dfs.client.file-block-storage-locations.timeout.millis</name>
<value>600000</value>
</property>
<property>
<name>dfs.namenode.kerberos.https.principal</name>
<value>mapred/hadoop.hadoop.com@HADOOP.COM</value>
</property>
<property>
<name>dfs.client.failover.connection.retries.on.timeouts</name>
<value>0</value>
</property>
<property>
<name>dfs.client.close.ack-timeout</name>
<value>900000</value>
</property>
<property>
<name>dfs.namenode.rpc-address.haclusterX4.remotenn1</name>
<value></value>
</property>
<property>
<name>dfs.namenode.rpc-address.haclusterX4.remotenn2</name>
<value></value>
</property>
<property>
<name>dfs.namenode.rpc-address.haclusterX.remotenn2</name>
<value>8.5.146.6:25000</value>
</property>
<property>
<name>oi.dfs.colocation.zookeeper.quorum</name>
<value>8-5-214-9:24002,8-5-214-8:24002,8-5-214-7:24002</value>
</property>
<property>
<name>dfs.namenode.rpc-address.haclusterX.remotenn1</name>
<value>8.5.146.7:25000</value>
</property>
<property>
<name>dfs.web.authentication.kerberos.principal</name>
<value>HTTP/_HOST@HADOOP.COM</value>
</property>
<property>
<name>dfs.client.socket-timeout</name>
<value>600000</value>
</property>
<property>
<name>dfs.encrypt.data.transfer.cipher.suites</name>
<value>AES/CTR/NoPadding</value>
</property>
<property>
<name>dfs.ha.namenodes.haclusterX2</name>
<value>remotenn1,remotenn2</value>
</property>
<property>
<name>dfs.ha.namenodes.haclusterX1</name>
<value>remotenn1,remotenn2</value>
</property>
<property>
<name>dfs.ha.namenodes.haclusterX4</name>
<value>remotenn1,remotenn2</value>
</property>
<property>
<name>dfs.client.socketcache.expiryMsec</name>
<value>3000</value>
</property>
<property>
<name>dfs.ha.namenodes.haclusterX3</name>
<value>remotenn1,remotenn2</value>
</property>
<property>
<name>dfs.namenode.rpc-address.haclusterX1.remotenn1</name>
<value></value>
</property>
<property>
<name>dfs.namenode.rpc-address.haclusterX1.remotenn2</name>
<value></value>
</property>
<property>
<name>dfs.datanode.socket.write.timeout</name>
<value>600000</value>
</property>
<property>
<name>dfs.client.failover.connection.retries</name>
<value>0</value>
</property>
<property>
<name>dfs.client.failover.proxy.provider.haclusterX</name>
<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>
<property>
<name>dfs.http.policy</name>
<value>HTTP_AND_HTTPS</value>
</property>
<property>
<name>dfs.client.failover.proxy.provider.hacluster</name>
<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>
<property>
<name>dfs.client.io-weight</name>
<value>10</value>
</property>
<property>
<name>dfs.domain.socket.path</name>
<value>/var/run/FusionInsight-HDFS/dn_socket</value>
</property>
<property>
<name>dfs.datanode.kerberos.principal</name>
<value>mapred/hadoop.hadoop.com@HADOOP.COM</value>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.policy</name>
<value>DEFAULT</value>
</property>
<property>
<name>dfs.client.failover.proxy.provider.haclusterX1</name>
<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>
<property>
<name>dfs.encrypt.data.transfer.algorithm</name>
<value>3des</value>
</property>
<property>
<name>dfs.client.read.shortcircuit</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.kerberos.principal</name>
<value>mapred/hadoop.hadoop.com@HADOOP.COM</value>
</property>
<property>
<name>dfs.client.failover.proxy.provider.haclusterX4</name>
<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>
<property>
<name>dfs.namenode.rpc-address.haclusterX2.remotenn1</name>
<value></value>
</property>
<property>
<name>dfs.client.failover.proxy.provider.haclusterX3</name>
<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>
<property>
<name>dfs.namenode.rpc-address.haclusterX2.remotenn2</name>
<value></value>
</property>
<property>
<name>dfs.client.failover.proxy.provider.haclusterX2</name>
<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>
<property>
<name>dfs.ha.namenodes.hacluster</name>
<value>100,101</value>
</property>
<property>
<name>ipc.client.connect.max.retries.on.timeouts</name>
<value>45</value>
</property>
<property>
<name>dfs.client.socketcache.capacity</name>
<value>16</value>
</property>
<property>
<name>dfs.blocksize</name>
<value>134217728</value>
</property>
<property>
<name>dfs.datanode.address</name>
<value>8-5-214-7:25009</value>
</property>
<property>
<name>dfs.encrypt.data.transfer</name>
<value>false</value>
</property>
<property>
<name>dfs.distcp</name>
<value>haclusterX,haclusterX1,haclusterX2,haclusterX3,haclusterX4</value>
</property>
<property>
<name>dfs.ha.namenodes.haclusterX</name>
<value>remotenn1,remotenn2</value>
</property>
<property>
<name>yarn.distcp.fs-limits.max-directory-items</name>
<value>10000000</value>
</property>
<property>
<name>dfs.datanode.socket.reuse.keepalive</name>
<value>4000</value>
</property>
<property>
<name>dfs.client.failover.max.attempts</name>
<value>10</value>
</property>
<property>
<name>dfs.namenode.rpc-address.haclusterX3.remotenn1</name>
<value></value>
</property>
<property>
<name>dfs.datanode.http.address</name>
<value>8-5-214-7:25010</value>
</property>
<property>
<name>dfs.namenode.rpc-address.haclusterX3.remotenn2</name>
<value></value>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.replication</name>
<value>2</value>
</property>
</configuration>
