<?xml version="1.0" encoding="UTF-8"?>
<configuration>
<property>
<name>dfs.use.dfs.network.topology</name>
<value>true</value>
</property>
<property>
<name>dfs.datanode.peer.stats.enabled</name>
<value>true</value>
</property>
<property>
<name>ipc.server.tcpnodelay</name>
<value>true</value>
</property>
<property>
<name>dfs.client.https.need-auth</name>
<value>false</value>
</property>
<property>
<name>dfs.replication</name>
<value>3</value>
</property>
<property>
<name>dfs.ha.fencing.ssh.private-key-files</name>
<value>/home/omm/.ssh/id_rsa</value>
</property>
<property>
<name>dfs.namenode.audit.log.async</name>
<value>false</value>
</property>
<property>
<name>dfs.auto.data.mover.custome.actions</name>
<value></value>
</property>
<property>
<name>fs.defaultFS.for.router-based-federation</name>
<value>hdfs://nsfed</value>
</property>
<property>
<name>dfs.namenode.kerberos.https.principal</name>
<value>hdfs/hadoop.hadoop.com@HADOOP.COM</value>
</property>
<property>
<name>dfs.namenode.servicerpc.port</name>
<value>25006</value>
</property>
<property>
<name>oi.dfs.colocation.zookeeper.session-timeout.ms</name>
<value>90000</value>
</property>
<property>
<name>dfs.disk.balancer.max.disk.throughputInMBperSec</name>
<value>10</value>
</property>
<property>
<name>ipc.server.handler.queue.size</name>
<value>100</value>
</property>
<property>
<name>dfs.namenode.observer.ids.hacluster</name>
<value></value>
</property>
<property>
<name>dfs.namenode.audit.log.debug.cmdlist</name>
<value>open,getfileinfo,getAclStatus</value>
</property>
<property>
<name>dfs.namenode.ec.policies.max.cellsize</name>
<value>4194304</value>
</property>
<property>
<name>dfs.client.failover.activeinfo.share.io.timeout.sec</name>
<value>5</value>
</property>
<property>
<name>dfs.namenode.replication.min</name>
<value>1</value>
</property>
<property>
<name>dfs.mover.auto.cron.expression</name>
<value>0 * * * *</value>
</property>
<property>
<name>dfs.client.socketcache.expiryMsec</name>
<value>3000</value>
</property>
<property>
<name>dfs.federation.router.admin-address</name>
<value>187-4-65-85:25020</value>
</property>
<property>
<name>dfs.namenode.fs-limits.min-block-size</name>
<value>1048576</value>
</property>
<property>
<name>dfs.namenode.http.policy</name>
<value>HTTPS_ONLY</value>
</property>
<property>
<name>dfs.namenode.acls.enabled</name>
<value>true</value>
</property>
<property>
<name>dfs.journalnode.keytab.file</name>
<value>/opt/huawei/Bigdata/FusionInsight_HD_6.5.1/install/FusionInsight-Hadoop-3.1.1/hadoop/keytabs/hdfs/hdfs.keytab</value>
</property>
<property>
<name>dfs.client.metadata.cache.enabled</name>
<value>false</value>
</property>
<property>
<name>ha.failover-controller.graceful-fence.rpc-timeout.ms</name>
<value>180000</value>
</property>
<property>
<name>dfs.namenode.datanode.registration.ip-hostname-check</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.path.based.cache.block.map.allocation.percent</name>
<value>0.25f</value>
</property>
<property>
<name>dfs.journalnode.kerberos.principal</name>
<value>hdfs/hadoop.hadoop.com@HADOOP.COM</value>
</property>
<property>
<name>dfs.client.failover.activeinfo.share.flag</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.edits.noeditlogchannelflush</name>
<value>false</value>
</property>
<property>
<name>dfs.web.authentication.kerberos.keytab</name>
<value>/opt/huawei/Bigdata/FusionInsight_HD_6.5.1/install/FusionInsight-Hadoop-3.1.1/hadoop/keytabs/hdfs/HTTP.keytab</value>
</property>
<property>
<name>dfs.namenode.rpc-address.hacluster.16</name>
<value>187-4-64-185:25000</value>
</property>
<property>
<name>hadoop.proxyuser.miner.groups</name>
<value>*</value>
</property>
<property>
<name>dfs.mover.auto.enable</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.rpc-address.hacluster.17</name>
<value>187-4-65-85:25000</value>
</property>
<property>
<name>dfs.balancer.auto.exclude.datanodes</name>
<value></value>
</property>
<property>
<name>ipc.25000.decay-scheduler.backoff.responsetime.thresholds</name>
<value>10000,20000,30000,40000</value>
</property>
<property>
<name>dfs.http.policy</name>
<value>HTTPS_ONLY</value>
</property>
<property>
<name>dfs.balancer.max-size-to-move</name>
<value>32212254720</value>
</property>
<property>
<name>dfs.client.failover.proxy.provider.hacluster</name>
<value>org.apache.hadoop.hdfs.server.namenode.ha.AdaptiveFailoverProxyProvider</value>
</property>
<property>
<name>dfs.namenode.replication.interval</name>
<value>3</value>
</property>
<property>
<name>dfs.namenode.safemode.min.datanodes</name>
<value>0</value>
</property>
<property>
<name>dfs.datanode.kerberos.principal</name>
<value>hdfs/hadoop.hadoop.com@HADOOP.COM</value>
</property>
<property>
<name>oi.dfs.colocation.zookeeper.lock.limit</name>
<value>10</value>
</property>
<property>
<name>dfs.webhdfs.enabled</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.delegation.token.max-lifetime</name>
<value>604800000</value>
</property>
<property>
<name>dfs.auto.data.mover.cron.expression</name>
<value>0 * * * *</value>
</property>
<property>
<name>dfs.namenode.avoid.write.stale.datanode</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.kerberos.principal</name>
<value>hdfs/hadoop.hadoop.com@HADOOP.COM</value>
</property>
<property>
<name>dfs.balancer.getBlocks.size</name>
<value>2147483648</value>
</property>
<property>
<name>dfs.balancer.auto.policy</name>
<value>blockpool</value>
</property>
<property>
<name>dfs.block.placement.ec.classname</name>
<value>org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant</value>
</property>
<property>
<name>dfs.namenode.num.extra.edits.retained</name>
<value>1000000</value>
</property>
<property>
<name>ipc.25000.callqueue.impl</name>
<value>java.util.concurrent.LinkedBlockingQueue</value>
</property>
<property>
<name>ipc.client.connect.max.retries.on.timeouts</name>
<value>45</value>
</property>
<property>
<name>dfs.namenode.servicerpc-address.hacluster.17</name>
<value>187-4-65-85:25006</value>
</property>
<property>
<name>dfs.namenode.servicerpc-address.hacluster.16</name>
<value>187-4-64-185:25006</value>
</property>
<property>
<name>dfs.namenode.directory-items.monitor</name>
<value>/tmp,/SparkJobHistory,/mr-history</value>
</property>
<property>
<name>dfs.client.failover.observer.auto-msync-period.hacluster</name>
<value>0ms</value>
</property>
<property>
<name>dfs.ha.tail-edits.in-progress</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.available-space-block-placement-policy.balanced-space-preference-fraction</name>
<value>0.6</value>
</property>
<property>
<name>dfs.client.failover.random.order</name>
<value>true</value>
</property>
<property>
<name>dfs.client-write-packet-size</name>
<value>262144</value>
</property>
<property>
<name>dfs.datanode.transfer.socket.send.buffer.size</name>
<value>131072</value>
</property>
<property>
<name>dfs.namenode.checkpoint.txns</name>
<value>5000000</value>
</property>
<property>
<name>dfs.client.block.write.retries</name>
<value>3</value>
</property>
<property>
<name>dfs.namenode.safemode.threshold-pct</name>
<value>0.999999</value>
</property>
<property>
<name>dfs.namenode.servicerpc-bind-host</name>
<value>187-4-65-85</value>
</property>
<property>
<name>dfs.namenode.kerberos.principal.pattern</name>
<value>*</value>
</property>
<property>
<name>dfs.namenode.http-address.hacluster.17</name>
<value>187-4-65-85:25002</value>
</property>
<property>
<name>dfs.namenode.replication.max-streams</name>
<value>64</value>
</property>
<property>
<name>dfs.namenode.http-address.hacluster.16</name>
<value>187-4-64-185:25002</value>
</property>
<property>
<name>dfs.namenode.keytab.file</name>
<value>/opt/huawei/Bigdata/FusionInsight_HD_6.5.1/install/FusionInsight-Hadoop-3.1.1/hadoop/keytabs/hdfs/hdfs.keytab</value>
</property>
<property>
<name>dfs.nameservices</name>
<value>hacluster,nsfed</value>
</property>
<property>
<name>ipc.client.idlethreshold</name>
<value>4000</value>
</property>
<property>
<name>dfs.namenode.file.close.num-committed-allowed</name>
<value>0</value>
</property>
<property>
<name>dfs.namenode.reconstruction.pending.timeout-sec</name>
<value>900</value>
</property>
<property>
<name>ipc.server.max.response.size</name>
<value>1048576</value>
</property>
<property>
<name>dfs.client.failover.connection.retries.on.timeouts</name>
<value>0</value>
</property>
<property>
<name>dfs.client.close.ack-timeout</name>
<value>900000</value>
</property>
<property>
<name>dfs.namenode.replication.work.multiplier.per.iteration</name>
<value>32</value>
</property>
<property>
<name>ipc.25000.backoff.enable</name>
<value>false</value>
</property>
<property>
<name>dfs.client.metadata.cache.pattern</name>
<value></value>
</property>
<property>
<name>dfs.namenode.directory-items.monitor.enabled</name>
<value>true</value>
</property>
<property>
<name>dfs.internal.nameservices</name>
<value>hacluster</value>
</property>
<property>
<name>dfs.disk.balancer.auto.enabled</name>
<value>false</value>
</property>
<property>
<name>dfs.ha.tail-edits.period.observer</name>
<value>15</value>
</property>
<property>
<name>dfs.image.compression.codec</name>
<value>org.apache.hadoop.io.compress.DefaultCodec</value>
</property>
<property>
<name>dfs.client.socket-timeout</name>
<value>600000</value>
</property>
<property>
<name>dfs.balancer.block-move.timeout</name>
<value>0</value>
</property>
<property>
<name>dfs.balancer.auto.maxDataNodesNum</name>
<value>5</value>
</property>
<property>
<name>dfs.namenode.replication.max-streams-hard-limit</name>
<value>128</value>
</property>
<property>
<name>dfs.datanode.socket.write.timeout</name>
<value>600000</value>
</property>
<property>
<name>dfs.auto.data.mover.enable</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.accesstime.precision</name>
<value>3600000</value>
</property>
<property>
<name>dfs.namenode.lifeline.rpc-bind-host</name>
<value>187-4-65-85</value>
</property>
<property>
<name>dfs.image.transfer.timeout</name>
<value>600000</value>
</property>
<property>
<name>ipc.25000.faircallqueue.decay-scheduler.thresholds</name>
<value></value>
</property>
<property>
<name>net.topology.nodegroup.aware</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.rpc-address.nsfed.19</name>
<value>187-4-65-85:25019</value>
</property>
<property>
<name>dfs.stream-buffer-size</name>
<value>4096</value>
</property>
<property>
<name>dfs.ha.namenodes.nsfed</name>
<value>20,19,18</value>
</property>
<property>
<name>dfs.namenode.invalidate.work.pct.per.iteration</name>
<value>0.32</value>
</property>
<property>
<name>dfs.namenode.rpc-address.nsfed.18</name>
<value>187-4-64-185:25019</value>
</property>
<property>
<name>dfs.datanode.outliers.report.interval</name>
<value>1800000</value>
</property>
<property>
<name>dfs.namenode.max.objects</name>
<value>0</value>
</property>
<property>
<name>dfs.router.nameservice</name>
<value>nsfed</value>
</property>
<property>
<name>dfs.bytes-per-checksum</name>
<value>512</value>
</property>
<property>
<name>dfs.cluster.administrators</name>
<value>hdfs hadoopmanager,supergroup,System_administrator_186</value>
</property>
<property>
<name>ha.failover-controller.new-active.rpc-timeout.ms</name>
<value>180000</value>
</property>
<property>
<name>dfs.encrypt.data.transfer.algorithm</name>
<value>3des</value>
</property>
<property>
<name>dfs.client.read.shortcircuit</name>
<value>true</value>
</property>
<property>
<name>dfs.federation.router.admin-address.list</name>
<value>187-4-65-67:25020,187-4-65-85:25020,187-4-64-185:25020</value>
</property>
<property>
<name>dfs.client.metadata.cache.expiry.sec</name>
<value>60s</value>
</property>
<property>
<name>dfs.namenode.jmx.url.prefix</name>
<value>https://187-4-65-85:25003</value>
</property>
<property>
<name>dfs.activenamenode.checkpoint.interval</name>
<value>12</value>
</property>
<property>
<name>dfs.namenode.https.port</name>
<value>25003</value>
</property>
<property>
<name>dfs.namenode.inode.attributes.provider.class</name>
<value>com.huawei.hadoop.adapter.hdfs.plugin.HWINodeAttributeProvider</value>
</property>
<property>
<name>net.topology.impl</name>
<value>org.apache.hadoop.net.NetworkTopology</value>
</property>
<property>
<name>dfs.client.failover.sleep.base.millis</name>
<value>500</value>
</property>
<property>
<name>dfs.permissions.superusergroup</name>
<value>supergroup</value>
</property>
<property>
<name>dfs.block.replicator.classname</name>
<value>org.apache.hadoop.hdfs.server.blockmanagement.AvailableSpaceBlockPlacementPolicy</value>
</property>
<property>
<name>dfs.namenode.fs-limits.max-directory-items</name>
<value>1048576</value>
</property>
<property>
<name>dfs.ha.log-roll.period</name>
<value>120</value>
</property>
<property>
<name>ipc.25000.faircallqueue.multiplexer.weights</name>
<value></value>
</property>
<property>
<name>dfs.client.socket.send.buffer.size</name>
<value>131072</value>
</property>
<property>
<name>dfs.ha.namenode.id</name>
<value>17</value>
</property>
<property>
<name>dfs.balancer.getBlocks.min-block-size</name>
<value>10485760</value>
</property>
<property>
<name>dfs.namenode.heartbeat.recheck-interval</name>
<value>300000</value>
</property>
<property>
<name>ipc.25000.identity-provider.impl</name>
<value>org.apache.hadoop.ipc.UserIdentityProvider</value>
</property>
<property>
<name>dfs.namenode.safemode.extension</name>
<value>15000</value>
</property>
<property>
<name>dfs.client.failover.sleep.max.millis</name>
<value>15000</value>
</property>
<property>
<name>dfs.namenode.rpc-address.nsfed.20</name>
<value>187-4-65-67:25019</value>
</property>
<property>
<name>dfs.client.failover.activeinfo.share.path</name>
<value>/tmp</value>
</property>
<property>
<name>dfs.datanode.transfer.socket.recv.buffer.size</name>
<value>131072</value>
</property>
<property>
<name>fs.permissions.umask-mode</name>
<value>022</value>
</property>
<property>
<name>audit.service.name</name>
<value>HDFS</value>
</property>
<property>
<name>hadoop.zk.hostname.list</name>
<value>187-4-64-185,187-4-65-85,187-4-65-67</value>
</property>
<property>
<name>dfs.journalnode.rpc.port</name>
<value>25012</value>
</property>
<property>
<name>dfs.observer.read.enable</name>
<value>true</value>
</property>
<property>
<name>ipc.namenode-rpc-port.need.replace</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.fs-limits.max-blocks-per-file</name>
<value>1048576</value>
</property>
<property>
<name>ipc.25000.faircallqueue.priority-levels</name>
<value>4</value>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.enable</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.ec.ignore.compatibility.check.during-upgrade</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.lifeline.handler.ratio</name>
<value>0.1</value>
</property>
<property>
<name>dfs.balancer.auto.maxIdleIterations</name>
<value>5</value>
</property>
<property>
<name>dfs.balancer.auto.enable</name>
<value>false</value>
</property>
<property>
<name>dfs.ha.zkfc.port</name>
<value>25015</value>
</property>
<property>
<name>net.topology.node.switch.mapping.impl</name>
<value>org.apache.hadoop.net.ScriptBasedMapping</value>
</property>
<property>
<name>dfs.storage.policy.enabled</name>
<value>true</value>
</property>
<property>
<name>ipc.25000.decay-scheduler.backoff.responsetime.enable</name>
<value>false</value>
</property>
<property>
<name>oi.dfs.colocation.zookeeper.quorum</name>
<value>187-4-64-185:24002,187-4-65-85:24002,187-4-65-67:24002</value>
</property>
<property>
<name>dfs.disk.balancer.block.tolerance.percent</name>
<value>10</value>
</property>
<property>
<name>ha.zookeeper.parent-znode</name>
<value>/hadoop-ha</value>
</property>
<property>
<name>dfs.namenode.shared.edits.dir.hacluster</name>
<value>qjournal://187-4-64-185:25012;187-4-65-67:25012;187-4-65-85:25012/hacluster</value>
</property>
<property>
<name>dfs.datanode.balance.max.concurrent.moves</name>
<value>32</value>
</property>
<property>
<name>dfs.datanode.block-pinning.enabled</name>
<value>false</value>
</property>
<property>
<name>dfs.encrypt.data.transfer.cipher.suites</name>
<value>AES/CTR/NoPadding</value>
</property>
<property>
<name>dfs.namenode.blocklocation.with.path</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.num.checkpoints.retained</name>
<value>3</value>
</property>
<property>
<name>dfs.blockplacement.mandatory.rackgroup.name</name>
<value></value>
</property>
<property>
<name>dfs.encrypt.data.transfer.cipher.key.bitlength</name>
<value>256</value>
</property>
<property>
<name>dfs.balancer.dispatcherThreads</name>
<value>512</value>
</property>
<property>
<name>dfs.permissions.enabled</name>
<value>true</value>
</property>
<property>
<name>dfs.disk.balancer.top.nodes.number</name>
<value>5</value>
</property>
<property>
<name>ha.zookeeper.quorum</name>
<value>187-4-64-185:24002,187-4-65-85:24002,187-4-65-67:24002</value>
</property>
<property>
<name>dfs.rackgroup.nextpolicy</name>
<value>org.apache.hadoop.hdfs.server.blockmanagement.AvailableSpaceBlockPlacementPolicy</value>
</property>
<property>
<name>dfs.namenode.stale.datanode.interval</name>
<value>30000</value>
</property>
<property>
<name>dfs.namenode.http.port</name>
<value>25002</value>
</property>
<property>
<name>dfs.disk.balancer.plan.threshold.percent</name>
<value>10</value>
</property>
<property>
<name>dfs.namenode.ec.system.default.policy</name>
<value>RS-6-3-1024k</value>
</property>
<property>
<name>dfs.namenode.https-address.hacluster.16</name>
<value>187-4-64-185:25003</value>
</property>
<property>
<name>dfs.namenode.https-address.hacluster.17</name>
<value>187-4-65-85:25003</value>
</property>
<property>
<name>dfs.domain.socket.path</name>
<value>/var/run/FusionInsight-HDFS/dn_socket</value>
</property>
<property>
<name>dfs.disk.balancer.max.disk.errors</name>
<value>5</value>
</property>
<property>
<name>dfs.namenode.handler.count</name>
<value>128</value>
</property>
<property>
<name>dfs.qjournal.write-txns.timeout.ms</name>
<value>20000</value>
</property>
<property>
<name>dfs.image.transfer.bandwidthPerSec</name>
<value>104857600</value>
</property>
<property>
<name>dfs.replication.max</name>
<value>512</value>
</property>
<property>
<name>dfs.namenode.name.dir</name>
<value>/srv/BigData/namenode</value>
</property>
<property>
<name>dfs.federation.router.store.driver.zk.parent-path</name>
<value>/hdfs-federation</value>
</property>
<property>
<name>ipc.client.kill.max</name>
<value>10</value>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.min-replication</name>
<value>2</value>
</property>
<property>
<name>dfs.balancer.block.filter.class</name>
<value>org.apache.hadoop.hdfs.server.balancer.BlockFilterWithNodeLabel</value>
</property>
<property>
<name>dfs.namenode.observer.enable</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.upgrade.nodelabel.xattr</name>
<value>true</value>
</property>
<property>
<name>dfs.block.access.token.enable</name>
<value>true</value>
</property>
<property>
<name>dfs.blocksize</name>
<value>134217728</value>
</property>
<property>
<name>dfs.datanode.fileio.profiling.sampling.percentage</name>
<value>20</value>
</property>
<property>
<name>dfs.namenode.lifeline.handler.count</name>
<value>16</value>
</property>
<property>
<name>ha.failover-controller.cli-check.rpc-timeout.ms</name>
<value>180000</value>
</property>
<property>
<name>dfs.balancer.auto.threshold</name>
<value>10</value>
</property>
<property>
<name>dfs.encrypt.data.transfer</name>
<value>false</value>
</property>
<property>
<name>dfs.namenode.write.stale.datanode.ratio</name>
<value>0.5f</value>
</property>
<property>
<name>multi.namenode.flag</name>
<value>value</value>
</property>
<property>
<name>dfs.disk.balancer.auto.cron.expression</name>
<value>0 1 * * 6</value>
</property>
<property>
<name>dfs.client.failover.max.attempts</name>
<value>20</value>
</property>
<property>
<name>dfs.mover.auto.hdfsfiles_or_dirs</name>
<value></value>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.replication</name>
<value>2</value>
</property>
<property>
<name>dfs.journalnode.kerberos.internal.spnego.principal</name>
<value>HTTP/_HOST@HADOOP.COM</value>
</property>
<property>
<name>dfs.hosts</name>
<value></value>
</property>
<property>
<name>dfs.client.read.shortcircuit.skip.checksum</name>
<value>true</value>
</property>
<property>
<name>dfs.datanode.synconclose</name>
<value>false</value>
</property>
<property>
<name>dfs.current.nameservice</name>
<value>hacluster</value>
</property>
<property>
<name>dfs.nameservices.mappings</name>
<value>[{"name":"hacluster","roleInstances":["16","17"],"relationInstances":["187.4.64.185","187.4.65.67","187.4.65.85"]}]</value>
</property>
<property>
<name>dfs.client.failover.proxy.provider.nsfed</name>
<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>
<property>
<name>dfs.client.file-block-storage-locations.timeout.millis</name>
<value>600000</value>
</property>
<property>
<name>dfs.namenode.delegation.token.renew-interval</name>
<value>86400000</value>
</property>
<property>
<name>dfs.namenode.retrycache.heap.percent</name>
<value>0.03f</value>
</property>
<property>
<name>dfs.image.loader.thread</name>
<value>0</value>
</property>
<property>
<name>dfs.web.authentication.kerberos.principal</name>
<value>HTTP/_HOST@HADOOP.COM</value>
</property>
<property>
<name>hadoop.http.authentication.cookie.domain</name>
<value></value>
</property>
<property>
<name>dfs.namenode.kerberos.internal.spnego.principal</name>
<value>HTTP/_HOST@HADOOP.COM</value>
</property>
<property>
<name>dfs.namenode.rpc-bind-host</name>
<value>187-4-65-85</value>
</property>
<property>
<name>dfs.image.compress</name>
<value>false</value>
</property>
<property>
<name>dfs.client.failover.connection.retries</name>
<value>0</value>
</property>
<property>
<name>dfs.namenode.plugins</name>
<value></value>
</property>
<property>
<name>dfs.namenode.lifeline.rpc.port</name>
<value>25005</value>
</property>
<property>
<name>dfs.client.metadata.cache.max.entries</name>
<value>65536</value>
</property>
<property>
<name>dfs.namenode.checkpoint.check.period</name>
<value>60</value>
</property>
<property>
<name>dfs.block.placement.xattr.list</name>
<value></value>
</property>
<property>
<name>dfs.federation.datanode</name>
<value>187-4-65-67:25008,187-4-65-85:25008,187-4-64-185:25008</value>
</property>
<property>
<name>dfs.namenode.retrycache.expirytime.millis</name>
<value>600000</value>
</property>
<property>
<name>dfs.ha.fencing.ssh.connect-timeout</name>
<value>10000</value>
</property>
<property>
<name>dfs.namenode.fs-limits.max-component-length</name>
<value>7999</value>
</property>
<property>
<name>dfs.namenode.service.handler.count</name>
<value>32</value>
</property>
<property>
<name>dfs.ha.fencing.methods</name>
<value>shell(/bin/true)</value>
</property>
<property>
<name>dfs.namenode.enable.retrycache</name>
<value>true</value>
</property>
<property>
<name>dfs.client.block.write.replace-datanode-on-failure.policy</name>
<value>ALWAYS</value>
</property>
<property>
<name>dfs.balancer.auto.stop.cron.expression</name>
<value></value>
</property>
<property>
<name>ipc.25000.faircallqueue.decay-scheduler.decay-factor</name>
<value>0.5</value>
</property>
<property>
<name>dfs.namenode.active_standby.ids.hacluster</name>
<value>16,17</value>
</property>
<property>
<name>dfs.ha.tail-edits.period</name>
<value>60000</value>
</property>
<property>
<name>ipc.25000.faircallqueue.decay-scheduler.period-ms</name>
<value>5000</value>
</property>
<property>
<name>dfs.ha.namenodes.hacluster</name>
<value>16,17</value>
</property>
<property>
<name>dfs.skip.health-check.nameservices</name>
<value></value>
</property>
<property>
<name>dfs.namenode.startup.delay.block.deletion.sec</name>
<value>3600</value>
</property>
<property>
<name>dfs.client.socketcache.capacity</name>
<value>16</value>
</property>
<property>
<name>dfs.namenode.edits.dir</name>
<value>/srv/BigData/namenode</value>
</property>
<property>
<name>dfs.image.loader.inode.partition</name>
<value>1048576</value>
</property>
<property>
<name>dfs.balancer.auto.bandwidthPerSec</name>
<value>20</value>
</property>
<property>
<name>dfs.namenode.rpc.port</name>
<value>25000</value>
</property>
<property>
<name>dfs.namenode.name.dir.restore</name>
<value>true</value>
</property>
<property>
<name>dfs.namenode.lifeline.rpc-address.hacluster.16</name>
<value>187-4-64-185:25005</value>
</property>
<property>
<name>dfs.heartbeat.interval</name>
<value>10</value>
</property>
<property>
<name>dfs.namenode.lifeline.rpc-address.hacluster.17</name>
<value>187-4-65-85:25005</value>
</property>
<property>
<name>dfs.datanode.lifeline.interval.seconds</name>
<value></value>
</property>
<property>
<name>dfs.support.append</name>
<value>true</value>
</property>
<property>
<name>dfs.balancer.auto.cron.expression</name>
<value>0 1 * * 6</value>
</property>
<property>
<name>dfs.datanode.socket.reuse.keepalive</name>
<value>4000</value>
</property>
<property>
<name>dfs.auto-datamovement.policy.class</name>
<value>com.huawei.hadoop.hdfs.datamovement.policy.DefaultDataMovementPolicy</value>
</property>
<property>
<name>dfs.namenode.checkpoint.period</name>
<value>3600</value>
</property>
<property>
<name>dfs.client.read.striped.threadpool.size</name>
<value>256</value>
</property>
<property>
<name>dfs.ha.automatic-failover.enabled</name>
<value>true</value>
</property>
</configuration>
